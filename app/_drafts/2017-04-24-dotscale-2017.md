---
layout: post
title: "dotScale 2017"
tags: dotscale
---

iggest dotscale ever, going to new venue next year
hashtag #dotScale, but wireless-less

# Neha Narkede
confluent.io/download

rise of real-time
stacks were paper and peiple
now digital, not only a better versionof wat has been done before, creating
a different versions

data on paper is static, date in difital is a stream
bold claim that all your data is event stream
same as what audrey neveu was saying at mixit two days ago
business evens, logs, sensor, monitoring, db. al og these are events, and events
are streams

top level is events cming, you react to them, you do a pipeline
a giant mess of all evets going everywhete from every source to ever destination

better to hace a streaing platform
looks a lot like the diafraùs of "ypr infra is a mess, move everthing o cloud
and it will be easier". Not convinced anymore.
not  afan of putting eerything in the same part? vendor lock.

using a streaming platfomr eases in pushing the same event from every plafomr
(mobile, api, desktip), as "a product was viewes), and react as pushing it to
haddop. simpliigy connectons
again, can push the event to more than jaddpop, but to more

not sure it will be easier. no sure all the events from all platfomrs will be
the same, and if w won't need to creat custom events everywhere and the
streaming pipeline will become a mandatory step without adding values

streaming platform can be done with kafka, that was build for that at LinkedIn
1.4 trillion messages/day

streaming
source conector will pull data to kafka, and sink connectors that will push it
somewhere else
lots of connecters, to stream anything to anything
move data from one step to another in a stream

processing:
real-time map reduce: storm, spark, flink. take stream of data, build an
aggregated one, extrat only relevant data

event-driven microservices: 
secuirty dasjboard to see where connections are not regular, see it in real time

can use kafka as the central piece of streaming data. pushing data realtime from
one part to aother, react to eents, mapdreduce. interesting in the way it is
presented. anyone can puhs, anyone can react to it.
insteas of pushing everything to a D and then displayi things on it, you can do
the same thing buy adpating in realtime.

can't replace everyting relatime at once. vteaye p,e fpr a, a^; sode nu sode/
yje, reùpe the old, and have more people connecting to it

allow anyone to push to kafka it will push to the db, like before. ut allow also
dashboard to connect to it to get realtime data, instead of analyzing it and
getting the utput
could be used at Algolia for realtime quota, analytics, monitoring
crazy idea: when indexing new data, realtime update of connected users? need to
build someting with pubnub.

# Adrian Cole
Pivolal / Zipkin

Observability
Logging, metric and tracing

eerything based on events.logging is recoridng events, metrics is data combined
from measuring event tracing is following te order of events to causal ordering

to find response time, you can find it in logs. 95ms
if we look at metrics as a whole, we can see if 95ms is slow or fast compared to
he others
traces let us know why it took 95ms, we can follow the path it went through

log is easy to read, to grep
metrcics can let you see trends
trace let you understand the cause, accross services

logs grow with traffic and verbosity
metrics don't grow even if raffic increased, we're still only doing map/reduce
and aggregating
but tracing also grows with trafic

reduce logs by ditching irrelevant data or filtering
for metrics, use a coarser grain
tracing, only use sampling, not all the requests/parts

logs let you find edge cases and monitoring black boxes
merics let you identify patterns and set alerts on thresholds
tracing let you understand "why"

most everyone has logs
less have metrics, and even less have tracing

zipkin is a project to read traces

# Fast builds

slow biold is a pain, fast build incrase velocity
bigger he code base, slower the complitauion
google has too many lines of code

build and test time are superlinear in a project lifetime
the more it grows, the lomore it has inlclude, complexity, and then the slower
it is to build

tricks on how to ake C++ compile faster, using require and a few sumbols
seemed really specific, and because I don't do any C++, no( into it that much

but not specificillay for C++;, want to applu wha they learn to other languages
to improve the CI at Google

can improve Compilers, code and build systems

code organisation
if dpeendencie are linked, it will create a large tree, and will slow down the
require lib induction
if you write simple tests that will simply load the only dependencies you need,
you can reduce build time by 40%

build
clean build is the first one, long
null builds are builds afterward, that will only build if there is a difference
avoid unnecessary build time, but be carefful to not discard tasks that are
interesting to do
try to avoid clean buikds as mch as opossible

clean uilds everything
you can also disribute it accross machnes, to do it in parallele
you can add caching as well on top of that
evert new step usually decrease by an order of magnitude the time taken to
compile

bazel.build
can buld everthing with one build system whataver the language
easier tfor developer to move from one language to another in the company
focus on android, ios, server side

# Mitchel Hashimoto

Scaling Security

sacling people in the company, scaling the number of applications in the company
infrasructure to maintain them, but also te nmber of applications.

Developer, Operator and Production; Either dev pass to ops to prod, or dev and
ops move together.
people got the devops thing, but how do your put eseucrity in the mix
security can be an afterthug for many people; now it's in the front of te line,
so people want to put security

to scale there are 3 ways:
do less
do it faster
do it in parallel
and uou can sometimes even do three of them

in security, you cannot do less. you have to do it faster, and do it in paallel

answer is to empower people to build secrure syetems. same question as to "how
to you empower people to build/manage infrastucture". you need to help more
people do it.



for developers, you want a powerfule API. they need the tools to build things
for ops, you need a solution that is easy to maonain and can run on commodity
hardware. need something that behave like everything else. no specificity, need
to work like the rest.
secuirty: strict usage controls, audit trails, clear threat models

Vault

Developers
JSON API on TLS, easy to consume
secret storage: I can write in a secret storage. just send the data, Vault will
keep t secure
hash+salt the pasword, bu everything else in the DB is in plain text. We need to
encrupt the rest of the db, we need to handle keys, keys rotating, etc.
Everytime you find a way to secure something, you need a way to secure the key
that secure that questions, but we ned other keys and so one. Vault seems to be
able to handle that
Vault also handles certifcate and verfication of certificates for TLS

ops
pure software, no hardware
stateless, the state is saved wherever you want, in any DB. Vault does one
things

Security
Fort Knox idea
everything is in one place, you keep i really secyure instead of tring to
replicate the same thing everywhere
n-person unsela, you need several people to do something dangerous

security should not be in one people hands, everone, from the devs to the ops
should do it. seucirty eople are doing it full time, and take the decisions, but
the others have the power to implement stuff eaisly. the secuirty eople ill the
the process and decisions, which algo to use, etc, do the periodical audits
they should not be reviewing every command, but give the big pictures and the
tools for others to do the right thing

developers make sure the data is secure, as well as the app
the oprs make sure the infra and netwokr is secure
seucirty does the core rules and proecess, pratcices and audits

"Trust, ut verufi at every level" eplxain that they need to encrupt sensitva
edata, let them know how to do that, but let them pick whc data is sensitive or
not

This guy did Vagrant for devs, Terraform/Packer for Ops, and Vault for Security.

In Vault, if a key is always accessib=ng some data and then accesisng some other
data, Vault could find it.
Go is "exceptionnaly mediocre". Does nt do anything super well, but can take
a junior developer and work on complicated projects in a week. Safety at the
language level

## LIghtning talks

### Graphs in Redis
Omar Qunsul
Redis is the most loved DB of developers
Added graph to Redis
neighbors, shortest path
qunsul.com/graph-redis

### use Muliple

Every business is to make money
increase income, or deducs costs
follow the metrics of the money
have alerts
use instances that cost less
design for failure, allow adding/removing elements
move everything from one cloud provider to another
call from account manager, saying, it's too expensive. reduce costs

speak a bit too fast
move a bit too much
not clear how you moved form one ro ano

## Causality

Pierre Chapuis
Interval Tree Clocks: Loical clock for distributed systems
Two events changing same data
how to know the order?
version vectors to avaoid clock timer because dtsributed
seems interestin, but didn't understand the vectors?
github.com/catwell/itc.lu


## Scaling out PostgreSQL

Why SQL. Isnt' nosql the answer to sclability?
sql is hard to scale, so we build new databases that scales better

SQL <=> relattional algebrae
Collect pulls all the date in one place and work on it
It's like "FROM", but if we tink in relationa elgebra we goot all the
metehmatical principlaes that goes with it
Project(collect(a, b, ...)) == collect(pojeatc(a)) + collectporject b)

in join, we have distributed properties. collect(a, b, ...) x collect (sa, sb,
sc) == collect(a x sa, b s sb))

one to one binding between SQL queries to mathematical algebra

meaning we can imlement a sclabale SQLdatabase by pushing some work to each
node, instead of aggregating everything on the network, then aggregate it

can create extensions in poysgre, to add or change any step of the query
execution pipeline. can then use posygre as a layer to implement the distributed
architecture in a cluster of postgresql.
can sens a complex query, methematical analyze it split it in smaller queries,
send the queries to be executed on each noe, and aggregate at the end. because
of the mathematical nature of it, you can reduce the number of network calls or
expensive queries that ate neded because you know the overall query.

works really well for multi-tenancy, hete each vesion of the app is for
a specific use rdata, like Gmail. 

## David Mazières

Internet-level consensus is practical

how tto get something agreed by all CAs in the orld
there is a mozilla list, but incomplete, not up t date, OS adds or tweaks to the
list
also organizations have ocal CAs

why?
why not having a global timestamp, to ppve documents
different log systemes. maybe ask authorities, but not everyone follow te same
authrotites, or even a good authroity can be revoked (like it happened with
Norton)

FBI asked apple to sign a bootloader. apple said no, bt we have no way to prove
if they did it or not
maybe we should make software updated visible truh software transparency
devices could refuse to install tings if updates are not sigened and publica and
that everyone could see it

would be a way to revoke our own software when we discover their is a leak in it


Fdeerated Byzantine Agreemant: FBA
picks a few slices of quromum
ony tryusts superset of one of my slices
if I care about one authority, I put it in all my slices

kind of an interesting system to not only trust one CA, but slices of quorum of
several quorum, recursively
hard to follow

Stellar Consensus Protocol


## Failures

Failure free operations require experience with failure
Stories about failure

call in themiddle of the night
16 people in the same call
all trying to do the same thing, loggin to the server
no one had any idea what to do

people are "doing somehing", but no coordination
then execs asked "spreadsheet about all the impacting customer"
instead of solving the problems, tryong to understand who was affected

morning after
=> you're to be blamed for this incident
no one knew what theissue was, but had t find who to blame
no framework on how to find the issue in production error

define, prepare and measure
check if an important metric is not owkring as usual. main metric, if goes down,
all-hands on deck
prepare te infra for black friday

failures should be unique, if not, automate the response
single resposibility principlae: one people o the error does one thing, not
everyone does the same thing
the expert that knows this part of the system should be investigating. multiple
people can investigating, but not two of them doing the same thing at the same
time

Incident COmmander: single source of truth for the incident call
notify that it's a major incident or not
veryfiy that experrts are resent
divide anc conquer, tell who does what
communicate between everyone

someone must document thetimeline of the incident resolutuion as it progresses

customer liaisnon with our external customers, tweets. inform the incidnt
commander of any interesting information from the customers

during a long incident, pass the command to someone elese, that is not rired

blameless post mortem
it's not because you fire someone that your app will become reliable

shit happens. it will. be prepared for it.
on-call empathy. being on the front line is hard, we need to rust peple fixing
stuff in production
people are the msot valuabke asset, automated eveyrthing elese.


## Sercing for the serve in servelers

Clay Smith, New relic

how do you build a fast serverless function

mobile app asking lambda functions through and API gateway.
hard to see what is going on

first an event trigger, lmabda runs, and then result, error ot timeout
so ou got a number of erreors, the nmber of tme you run the function, and the
durations. the number of time and duration will lpact how much you'll pay

hard to debug
managed to do a ssh tunnel between the lambda and the machine
timeout of 5mn, hard to debug, but could work
can get the CPU, RAM and Network speed

understands that lmabda is a partition on a large AWS VM
you can check from inside a lambda if it's a cold start or warm. if warm, you
can try to keep it warm

seems hackish, investigating what is running the lmabda, reverse engineering

analyzing the machine where the lambdas are running, how long they stay online,
what subnet they are one

doing your own Faas require e very good scheuling algo, to keep things
runningsjust long enough and replace the underlyong machine transparently

FaaS is for a computational intensive task, done only occasionaly, in response
to a specific event.


## Thomas Ferreira / Dailymotion
won the puppet prize

## James Cammarata
Ansible

Watomation, bad automation

FB had an issue, and an automated system to deal with it. but so many errors and
sending all errors to their db, and DDOS the DB

`rm -rf {{path}}/{{some_file}}` in an ansible playbootk (was an hoax)

if bad input to auomatoin, can autmate the destruction of too many things

if you do someting ùanually, you'll forget things
manual == hman erros
with micros ervice,s you have more points of fialures, middlemawre, LB, etc

some old legacy system that contain the business logicc dont' ave much
protections
still, we need to keep automaying things
automaing let us not do the same mistkes wice
but we need to do the mistake at least once

if it has a remote API, or if you can talk to it, you can automate it. Ansible
helps with that

ut most of the issues in 2016 were form DDOS attacks and BGP configuration
mistakes (BGP? protocol used for different network to cmmunicate).

Ansible let you add conditional options before applong code. like if a specific
variable is in accesptable boundarires

use builtin ansible order instead og using custom shell
alos prefix variables so you don't collide variables between several ansible
configs
keep each element simple so you can more easily spot what things are doing. if
it's sipke, it's easy t maintain

## Andrew Shafer

Deep Devops
leraning to learn
Puppet

Ego presentation,. automating systems
"i'm gonna talk a lot about me and do some poor points". True.
talked a bit too much about himself

"everyone is a devops", different definitions
not really clear

automation is not helping a human, its doing something totally automatically
ou can put it in container and it piles up

volution in fossils comes in student jumps. nothing changes at all, then
a catasrophy, and everything has to change at once

devops is automating, changing and sharing informatiosn (I think that's the
point og the talk,np tusre)

can't slolve it with tech only, not with human only. it's both
need to adapt

## Ben Hindman

Distributed Systems should operate themselves

distribted sustems are not staeless microservices
we need csensus, state, replicaion, etc
it exists, it's hard to build, it's arder yto operatie

tose systems sjould be able to opereta, deloy, patch, etc themeseves

operators don't hva ethe all knowledge of how to automate everythin, now
everything that is happening in the systsem

on linux hen an app needs to scake p ut ass the OS for more memory, r create
anew thread
why can't we do the same on cloud?

distributed systems need some kind of interface to communicate with the system
as a whole
and the OS should be able to callback to the applications if needed
let each app delete the data unneeded when asked, istead of aving the OS decide
how to swap the momery

OS does not have the needed knowledge of application execution to male optimal
decisions
applicatopn needs ans emantics can't e esaisly or efficiently expressed between
the app and the OS

apps could tell the OS that it's going down. the OS itself could ake sure
everything works the same, instead of asking the humans to make sure everything
works correctly

We need a bi-directional interface between apps and cloud OS

express your need, pass it to the system (Docker Swarm, Maraton, Kubernets) and
let it run it
do they have enough knowledge to make optimal decisions? can the apps easily
express what they do to the overlyong OS
If it's stateless microservices yes. If not... no so much
we have humans than write scripts to do that

as an industry we should strive to build a std interface that distrbuted systems
can leerage. this interface must be bidirectional
how to scale distributed systems? we should let them scale themselves.






## Conclusion

Not that many talks about micro-services. Several talks about adding a main
entry point thay does a lot (Vault, Stream center). We're back to the ESB
